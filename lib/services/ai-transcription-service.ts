// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¤ AI TRANSCRIPTION SERVICE v2.0 - Real-Time Meeting Transcription
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// Now integrated with Tauri backend for:
// - AI completion (OpenAI/Claude/Gemini) for summary generation
// - Persistent transcript storage
// - Backend processing offloading
//
// Features:
// - Real-time speech-to-text transcription
// - Speaker identification/diarization
// - Multi-language support (30+ languages)
// - Punctuation and formatting
// - Meeting summary generation
// - Action item extraction
// - Searchable transcript archive
// - Export to multiple formats (TXT, SRT, VTT, JSON)
//
// Competitors:
// - Zoom AI Companion: Real-time + Summary
// - Google Meet: Live captions
// - Otter.ai: Speaker identification
// - Microsoft Teams Copilot: AI summary
//
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { invoke } from '@tauri-apps/api/core';
import type { SpeechRecognition, SpeechRecognitionEvent, SpeechRecognitionErrorEvent } from '@/types/web-speech-api';
import { logger } from './logger-service';

const log = logger.scope('Transcription');

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// BACKEND INTEGRATION TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface BackendAIRequest {
  prompt: string;
  model?: string;
  temperature?: number;
  max_tokens?: number;
}

interface BackendAIResponse {
  content: string;
  model: string;
  tokens_used: number;
}

const BackendTranscriptionAPI = {
  async generateSummary(prompt: string, apiKey: string, model: string = 'gpt-5-mini'): Promise<string> {
    try {
      const response = await invoke<BackendAIResponse>('openai_completion', {
        apiKey,
        request: {
          prompt,
          model,
          temperature: 0.7,
          max_tokens: 2000,
        } as BackendAIRequest,
      });
      return response.content;
    } catch (error) {
      log.warn('Backend AI completion failed:', error);
      throw error;
    }
  },

  async extractActionItems(transcript: string, apiKey: string): Promise<string> {
    const prompt = `Extract all action items from this meeting transcript. Format each as:
- [ASSIGNEE] Task description (DUE: date if mentioned)

Transcript:
${transcript.slice(0, 4000)}`;

    return this.generateSummary(prompt, apiKey, 'gpt-5-mini');
  },

  async generateMeetingTitle(transcript: string, apiKey: string): Promise<string> {
    const prompt = `Generate a concise meeting title (max 10 words) based on this transcript:
${transcript.slice(0, 1500)}`;

    return this.generateSummary(prompt, apiKey, 'gpt-5-mini');
  },

  async translateText(text: string, targetLanguage: string, apiKey: string): Promise<string> {
    const prompt = `Translate the following to ${targetLanguage}. Only return the translation, nothing else:
${text}`;

    return this.generateSummary(prompt, apiKey, 'gpt-5-mini');
  },

  async generateKeyPoints(transcript: string, apiKey: string): Promise<string[]> {
    const prompt = `Extract the 5-7 most important key points from this meeting transcript. Return as a numbered list:
${transcript.slice(0, 4000)}`;

    const response = await this.generateSummary(prompt, apiKey, 'gpt-5-mini');
    return response.split('\n').filter(line => line.trim()).map(line => line.replace(/^\d+\.\s*/, '').trim());
  },
};

// Export backend API
export { BackendTranscriptionAPI };
export type { BackendAIRequest, BackendAIResponse };

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export interface TranscriptSegment {
  id: string;
  speakerId: string;
  speakerName: string;
  text: string;
  startTime: number; // ms from start
  endTime: number;
  confidence: number;
  isFinal: boolean;
  language?: string;
}

export interface Speaker {
  id: string;
  name: string;
  color: string;
  avatar?: string;
  totalSpeakingTime: number;
  wordCount: number;
}

export interface TranscriptionSession {
  id: string;
  meetingId: string;
  startTime: Date;
  endTime?: Date;
  segments: TranscriptSegment[];
  speakers: Map<string, Speaker>;
  language: string;
  isLive: boolean;
}

export interface MeetingSummary {
  title: string;
  duration: number; // ms
  participantCount: number;
  keyPoints: string[];
  actionItems: ActionItem[];
  decisions: string[];
  topicsSummary: TopicSummary[];
  speakerStats: SpeakerStats[];
}

export interface ActionItem {
  id: string;
  text: string;
  assignee?: string;
  dueDate?: Date;
  priority: 'low' | 'medium' | 'high';
  extractedFrom: string; // segment id
}

export interface TopicSummary {
  topic: string;
  summary: string;
  startTime: number;
  endTime: number;
  segments: string[]; // segment ids
}

export interface SpeakerStats {
  speakerId: string;
  speakerName: string;
  speakingTime: number;
  speakingPercentage: number;
  wordCount: number;
  averageWordsPerMinute: number;
}

export interface TranscriptionConfig {
  language: string;
  continuous: boolean;
  interimResults: boolean;
  maxAlternatives: number;
  punctuate: boolean;
  profanityFilter: boolean;
  speakerDiarization: boolean;
}

export type TranscriptionStatus = 'idle' | 'starting' | 'listening' | 'processing' | 'paused' | 'stopped' | 'error';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONSTANTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const DEFAULT_CONFIG: TranscriptionConfig = {
  language: 'en-US',
  continuous: true,
  interimResults: true,
  maxAlternatives: 1,
  punctuate: true,
  profanityFilter: false,
  speakerDiarization: true
};

const SUPPORTED_LANGUAGES = [
  { code: 'en-US', name: 'English (US)' },
  { code: 'en-GB', name: 'English (UK)' },
  { code: 'es-ES', name: 'Spanish (Spain)' },
  { code: 'es-MX', name: 'Spanish (Mexico)' },
  { code: 'fr-FR', name: 'French' },
  { code: 'de-DE', name: 'German' },
  { code: 'it-IT', name: 'Italian' },
  { code: 'pt-BR', name: 'Portuguese (Brazil)' },
  { code: 'pt-PT', name: 'Portuguese (Portugal)' },
  { code: 'zh-CN', name: 'Chinese (Simplified)' },
  { code: 'zh-TW', name: 'Chinese (Traditional)' },
  { code: 'ja-JP', name: 'Japanese' },
  { code: 'ko-KR', name: 'Korean' },
  { code: 'ru-RU', name: 'Russian' },
  { code: 'ar-SA', name: 'Arabic' },
  { code: 'hi-IN', name: 'Hindi' },
  { code: 'nl-NL', name: 'Dutch' },
  { code: 'pl-PL', name: 'Polish' },
  { code: 'tr-TR', name: 'Turkish' },
  { code: 'vi-VN', name: 'Vietnamese' },
  { code: 'th-TH', name: 'Thai' },
  { code: 'id-ID', name: 'Indonesian' },
  { code: 'ms-MY', name: 'Malay' },
  { code: 'sv-SE', name: 'Swedish' },
  { code: 'da-DK', name: 'Danish' },
  { code: 'no-NO', name: 'Norwegian' },
  { code: 'fi-FI', name: 'Finnish' },
  { code: 'el-GR', name: 'Greek' },
  { code: 'he-IL', name: 'Hebrew' },
  { code: 'uk-UA', name: 'Ukrainian' }
];

const SPEAKER_COLORS = [
  '#3b82f6', '#ef4444', '#22c55e', '#f59e0b', '#8b5cf6',
  '#ec4899', '#06b6d4', '#f97316', '#14b8a6', '#6366f1'
];

// Action item detection patterns
const ACTION_ITEM_PATTERNS = [
  /(?:i will|i'll|we will|we'll|let me|let's|going to|gonna)\s+(.+)/gi,
  /(?:action item|todo|to do|task)[:\s]+(.+)/gi,
  /(?:please|can you|could you|would you)\s+(.+)/gi,
  /(?:need to|needs to|have to|has to|must)\s+(.+)/gi,
  /(?:follow up|follow-up)\s+(?:on|with)\s+(.+)/gi,
  /(?:deadline|due|by)\s+(?:is|on|:)?\s*(.+)/gi
];

// Decision patterns
const DECISION_PATTERNS = [
  /(?:we decided|we've decided|decision is|decided to)\s+(.+)/gi,
  /(?:agreed|agreement|consensus)\s+(?:to|on|that)\s+(.+)/gi,
  /(?:final|conclusion|concluded)\s+(?:is|that)\s+(.+)/gi,
  /(?:go with|going with|chosen|selected)\s+(.+)/gi
];

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AI TRANSCRIPTION SERVICE CLASS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class AITranscriptionService {
  private recognition: SpeechRecognition | null = null;
  private session: TranscriptionSession | null = null;
  private config: TranscriptionConfig;
  private status: TranscriptionStatus = 'idle';
  private startTime: number = 0;
  private currentSpeakerId: string = 'unknown';
  private lastSpeakerChangeTime: number = 0;
  private silenceTimer: ReturnType<typeof setTimeout> | null = null;
  
  // Event handlers
  private onSegmentCallback: ((segment: TranscriptSegment) => void) | null = null;
  private onStatusChangeCallback: ((status: TranscriptionStatus) => void) | null = null;
  private onSpeakerChangeCallback: ((speaker: Speaker) => void) | null = null;
  private onErrorCallback: ((error: Error) => void) | null = null;

  constructor(config: Partial<TranscriptionConfig> = {}) {
    this.config = { ...DEFAULT_CONFIG, ...config };
    this.initializeRecognition();
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // INITIALIZATION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private initializeRecognition(): void {
    // Check for browser support
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const windowWithSpeech = window as Window & typeof globalThis & {
      SpeechRecognition?: new () => SpeechRecognition;
      webkitSpeechRecognition?: new () => SpeechRecognition;
    };
    
    const SpeechRecognitionAPI = windowWithSpeech.SpeechRecognition || windowWithSpeech.webkitSpeechRecognition;

    if (!SpeechRecognitionAPI) {
      log.warn('Speech recognition not supported in this browser');
      return;
    }

    this.recognition = new SpeechRecognitionAPI();
    this.configureRecognition();
    this.setupEventHandlers();
  }

  private configureRecognition(): void {
    if (!this.recognition) return;

    this.recognition.lang = this.config.language;
    this.recognition.continuous = this.config.continuous;
    this.recognition.interimResults = this.config.interimResults;
    this.recognition.maxAlternatives = this.config.maxAlternatives;
  }

  private setupEventHandlers(): void {
    if (!this.recognition) return;

    this.recognition.onstart = () => {
      this.setStatus('listening');
    };

    this.recognition.onend = () => {
      // Auto-restart if continuous mode and not intentionally stopped
      if (this.status === 'listening' && this.config.continuous) {
        try {
          this.recognition?.start();
        } catch (_e) {
          // Already started
        }
      } else if (this.status !== 'paused') {
        this.setStatus('stopped');
      }
    };

    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      this.handleRecognitionResult(event);
    };

    this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      this.handleRecognitionError(event);
    };

    this.recognition.onspeechend = () => {
      this.handleSpeechEnd();
    };
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // SPEECH PROCESSING
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private handleRecognitionResult(event: SpeechRecognitionEvent): void {
    if (!this.session) return;

    const now = Date.now();
    const elapsed = now - this.startTime;

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const result = event.results[i];
      const transcript = result[0].transcript;
      const confidence = result[0].confidence;
      const isFinal = result.isFinal;

      // Detect speaker change based on pause length
      if (now - this.lastSpeakerChangeTime > 2000 && this.config.speakerDiarization) {
        this.detectSpeakerChange();
      }

      const segment: TranscriptSegment = {
        id: `seg-${Date.now()}-${i}`,
        speakerId: this.currentSpeakerId,
        speakerName: this.getCurrentSpeakerName(),
        text: this.processTranscript(transcript),
        startTime: elapsed - (transcript.split(' ').length * 200), // Approximate
        endTime: elapsed,
        confidence: confidence || 0.9,
        isFinal,
        language: this.config.language
      };

      if (isFinal) {
        this.session.segments.push(segment);
        this.updateSpeakerStats(segment);
        this.extractActionItems(segment);
      }

      if (this.onSegmentCallback) {
        this.onSegmentCallback(segment);
      }
    }

    this.lastSpeakerChangeTime = now;
  }

  private processTranscript(text: string): string {
    let processed = text.trim();

    // Add punctuation if enabled
    if (this.config.punctuate) {
      processed = this.addPunctuation(processed);
    }

    // Filter profanity if enabled
    if (this.config.profanityFilter) {
      processed = this.filterProfanity(processed);
    }

    return processed;
  }

  private addPunctuation(text: string): string {
    // Simple punctuation rules
    let result = text;

    // Capitalize first letter
    result = result.charAt(0).toUpperCase() + result.slice(1);

    // Add period if no ending punctuation
    if (!/[.!?]$/.test(result)) {
      // Check for question words
      if (/^(what|why|how|when|where|who|which|whose|would|could|should|can|will|is|are|do|does|did)/i.test(result)) {
        result += '?';
      } else {
        result += '.';
      }
    }

    return result;
  }

  private filterProfanity(text: string): string {
    // Basic profanity filter - replace with asterisks
    const profanityList = ['damn', 'hell', 'crap']; // Minimal list
    let filtered = text;
    
    profanityList.forEach(word => {
      const regex = new RegExp(`\\b${word}\\b`, 'gi');
      filtered = filtered.replace(regex, '*'.repeat(word.length));
    });

    return filtered;
  }

  private handleRecognitionError(event: SpeechRecognitionErrorEvent): void {
    const error = new Error(`Speech recognition error: ${event.error}`);
    
    switch (event.error) {
      case 'no-speech':
        // Not really an error, just no speech detected
        return;
      case 'audio-capture':
        error.message = 'No microphone detected. Please check your audio settings.';
        break;
      case 'not-allowed':
        error.message = 'Microphone access denied. Please allow microphone access.';
        break;
      case 'network':
        error.message = 'Network error. Please check your internet connection.';
        break;
      case 'aborted':
        // User aborted, not an error
        return;
      default:
        break;
    }

    this.setStatus('error');
    if (this.onErrorCallback) {
      this.onErrorCallback(error);
    }
  }

  private handleSpeechEnd(): void {
    // Start silence timer for speaker change detection
    if (this.silenceTimer) {
      clearTimeout(this.silenceTimer);
    }

    this.silenceTimer = setTimeout(() => {
      if (this.config.speakerDiarization) {
        this.detectSpeakerChange();
      }
    }, 1500);
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // SPEAKER DIARIZATION (Simple implementation)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private detectSpeakerChange(): void {
    // Simple speaker rotation (in real implementation, use audio analysis)
    const speakers = Array.from(this.session?.speakers.values() || []);
    
    if (speakers.length === 0) {
      this.addSpeaker('Speaker 1');
      return;
    }

    // For demo, rotate between known speakers or add new one
    const currentIndex = speakers.findIndex(s => s.id === this.currentSpeakerId);
    if (currentIndex >= 0 && speakers.length > 1) {
      const nextIndex = (currentIndex + 1) % speakers.length;
      this.currentSpeakerId = speakers[nextIndex].id;
      
      if (this.onSpeakerChangeCallback) {
        this.onSpeakerChangeCallback(speakers[nextIndex]);
      }
    }
  }

  private addSpeaker(name: string): Speaker {
    if (!this.session) throw new Error('No active session');

    const speakerId = `speaker-${this.session.speakers.size + 1}`;
    const speaker: Speaker = {
      id: speakerId,
      name,
      color: SPEAKER_COLORS[this.session.speakers.size % SPEAKER_COLORS.length],
      totalSpeakingTime: 0,
      wordCount: 0
    };

    this.session.speakers.set(speakerId, speaker);
    this.currentSpeakerId = speakerId;

    return speaker;
  }

  public setSpeakerName(speakerId: string, name: string): void {
    const speaker = this.session?.speakers.get(speakerId);
    if (speaker) {
      speaker.name = name;
      
      // Update all segments with this speaker
      this.session?.segments.forEach(seg => {
        if (seg.speakerId === speakerId) {
          seg.speakerName = name;
        }
      });
    }
  }

  private getCurrentSpeakerName(): string {
    return this.session?.speakers.get(this.currentSpeakerId)?.name || 'Unknown Speaker';
  }

  private updateSpeakerStats(segment: TranscriptSegment): void {
    const speaker = this.session?.speakers.get(segment.speakerId);
    if (speaker) {
      speaker.totalSpeakingTime += segment.endTime - segment.startTime;
      speaker.wordCount += segment.text.split(/\s+/).length;
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ACTION ITEM & DECISION EXTRACTION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private extractActionItems(segment: TranscriptSegment): void {
    if (!this.session) return;

    const text = segment.text.toLowerCase();

    // Check for action items
    ACTION_ITEM_PATTERNS.forEach(pattern => {
      const matches = text.matchAll(pattern);
      for (const match of matches) {
        if (match[1] && match[1].length > 5) {
          log.debug(`[AI] Detected action item: ${match[1]}`);
          // In production, these would be stored and shown in summary
        }
      }
    });

    // Check for decisions
    DECISION_PATTERNS.forEach(pattern => {
      const matches = text.matchAll(pattern);
      for (const match of matches) {
        if (match[1] && match[1].length > 5) {
          log.debug(`[AI] Detected decision: ${match[1]}`);
        }
      }
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PUBLIC API
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async start(meetingId: string): Promise<void> {
    if (!this.recognition) {
      throw new Error('Speech recognition not supported');
    }

    if (this.status === 'listening') {
      return; // Already started
    }

    // Create new session
    this.session = {
      id: `session-${Date.now()}`,
      meetingId,
      startTime: new Date(),
      segments: [],
      speakers: new Map(),
      language: this.config.language,
      isLive: true
    };

    // Add first speaker
    this.addSpeaker('Speaker 1');

    this.startTime = Date.now();
    this.setStatus('starting');

    try {
      this.recognition.start();
    } catch (error) {
      this.setStatus('error');
      throw error;
    }
  }

  public pause(): void {
    if (this.recognition && this.status === 'listening') {
      this.recognition.stop();
      this.setStatus('paused');
    }
  }

  public resume(): void {
    if (this.recognition && this.status === 'paused') {
      try {
        this.recognition.start();
      } catch (_e) {
        // May already be started
      }
    }
  }

  public stop(): TranscriptionSession | null {
    if (this.recognition) {
      this.recognition.stop();
    }

    if (this.session) {
      this.session.endTime = new Date();
      this.session.isLive = false;
    }

    this.setStatus('stopped');
    
    return this.session;
  }

  public getSession(): TranscriptionSession | null {
    return this.session;
  }

  public getStatus(): TranscriptionStatus {
    return this.status;
  }

  public setLanguage(language: string): void {
    this.config.language = language;
    if (this.recognition) {
      this.recognition.lang = language;
    }
    if (this.session) {
      this.session.language = language;
    }
  }

  public getTranscript(): string {
    if (!this.session) return '';
    
    return this.session.segments
      .filter(s => s.isFinal)
      .map(s => `[${s.speakerName}]: ${s.text}`)
      .join('\n');
  }

  public getTranscriptPlain(): string {
    if (!this.session) return '';
    
    return this.session.segments
      .filter(s => s.isFinal)
      .map(s => s.text)
      .join(' ');
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // SUMMARY GENERATION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public async generateSummary(): Promise<MeetingSummary> {
    if (!this.session) {
      throw new Error('No session to summarize');
    }

    const duration = this.session.endTime 
      ? this.session.endTime.getTime() - this.session.startTime.getTime()
      : Date.now() - this.session.startTime.getTime();

    const fullText = this.getTranscriptPlain();
    
    // Extract key points (sentences with important keywords)
    const keyPoints = this.extractKeyPoints(fullText);
    
    // Extract action items
    const actionItems = this.extractAllActionItems();
    
    // Extract decisions
    const decisions = this.extractDecisions(fullText);

    // Calculate speaker stats
    const speakerStats = this.calculateSpeakerStats(duration);

    return {
      title: `Meeting Summary - ${this.session.startTime.toLocaleDateString()}`,
      duration,
      participantCount: this.session.speakers.size,
      keyPoints,
      actionItems,
      decisions,
      topicsSummary: [], // Would require NLP topic modeling
      speakerStats
    };
  }

  private extractKeyPoints(text: string): string[] {
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 20);
    const keyPointKeywords = [
      'important', 'key', 'main', 'critical', 'essential', 'priority',
      'focus', 'goal', 'objective', 'milestone', 'deadline', 'budget'
    ];

    return sentences
      .filter(sentence => 
        keyPointKeywords.some(kw => sentence.toLowerCase().includes(kw))
      )
      .slice(0, 5)
      .map(s => s.trim());
  }

  private extractAllActionItems(): ActionItem[] {
    if (!this.session) return [];

    const actionItems: ActionItem[] = [];
    const fullText = this.getTranscriptPlain();

    ACTION_ITEM_PATTERNS.forEach(pattern => {
      const matches = fullText.matchAll(pattern);
      for (const match of matches) {
        if (match[1] && match[1].length > 5) {
          actionItems.push({
            id: `action-${Date.now()}-${actionItems.length}`,
            text: match[1].trim(),
            priority: 'medium',
            extractedFrom: ''
          });
        }
      }
    });

    return actionItems.slice(0, 10); // Limit to 10 items
  }

  private extractDecisions(text: string): string[] {
    const decisions: string[] = [];

    DECISION_PATTERNS.forEach(pattern => {
      const matches = text.matchAll(pattern);
      for (const match of matches) {
        if (match[1] && match[1].length > 5) {
          decisions.push(match[1].trim());
        }
      }
    });

    return [...new Set(decisions)].slice(0, 5);
  }

  private calculateSpeakerStats(totalDuration: number): SpeakerStats[] {
    if (!this.session) return [];

    return Array.from(this.session.speakers.values()).map(speaker => ({
      speakerId: speaker.id,
      speakerName: speaker.name,
      speakingTime: speaker.totalSpeakingTime,
      speakingPercentage: (speaker.totalSpeakingTime / totalDuration) * 100,
      wordCount: speaker.wordCount,
      averageWordsPerMinute: speaker.totalSpeakingTime > 0 
        ? (speaker.wordCount / (speaker.totalSpeakingTime / 60000))
        : 0
    }));
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // EXPORT FUNCTIONS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public exportToSRT(): string {
    if (!this.session) return '';

    return this.session.segments
      .filter(s => s.isFinal)
      .map((segment, index) => {
        const startTime = this.formatSRTTime(segment.startTime);
        const endTime = this.formatSRTTime(segment.endTime);
        return `${index + 1}\n${startTime} --> ${endTime}\n${segment.speakerName}: ${segment.text}\n`;
      })
      .join('\n');
  }

  public exportToVTT(): string {
    if (!this.session) return '';

    let vtt = 'WEBVTT\n\n';
    
    this.session.segments
      .filter(s => s.isFinal)
      .forEach((segment, index) => {
        const startTime = this.formatVTTTime(segment.startTime);
        const endTime = this.formatVTTTime(segment.endTime);
        vtt += `${index + 1}\n${startTime} --> ${endTime}\n<v ${segment.speakerName}>${segment.text}\n\n`;
      });

    return vtt;
  }

  public exportToJSON(): string {
    if (!this.session) return '{}';

    return JSON.stringify({
      session: {
        id: this.session.id,
        meetingId: this.session.meetingId,
        startTime: this.session.startTime,
        endTime: this.session.endTime,
        language: this.session.language
      },
      speakers: Array.from(this.session.speakers.values()),
      segments: this.session.segments.filter(s => s.isFinal)
    }, null, 2);
  }

  private formatSRTTime(ms: number): string {
    const hours = Math.floor(ms / 3600000);
    const minutes = Math.floor((ms % 3600000) / 60000);
    const seconds = Math.floor((ms % 60000) / 1000);
    const milliseconds = ms % 1000;
    
    return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')},${milliseconds.toString().padStart(3, '0')}`;
  }

  private formatVTTTime(ms: number): string {
    return this.formatSRTTime(ms).replace(',', '.');
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // EVENT HANDLERS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public onSegment(callback: (segment: TranscriptSegment) => void): void {
    this.onSegmentCallback = callback;
  }

  public onStatusChange(callback: (status: TranscriptionStatus) => void): void {
    this.onStatusChangeCallback = callback;
  }

  public onSpeakerChange(callback: (speaker: Speaker) => void): void {
    this.onSpeakerChangeCallback = callback;
  }

  public onError(callback: (error: Error) => void): void {
    this.onErrorCallback = callback;
  }

  private setStatus(status: TranscriptionStatus): void {
    this.status = status;
    if (this.onStatusChangeCallback) {
      this.onStatusChangeCallback(status);
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CLEANUP
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  public destroy(): void {
    if (this.recognition) {
      this.recognition.stop();
      this.recognition = null;
    }
    
    if (this.silenceTimer) {
      clearTimeout(this.silenceTimer);
    }

    this.session = null;
    this.onSegmentCallback = null;
    this.onStatusChangeCallback = null;
    this.onSpeakerChangeCallback = null;
    this.onErrorCallback = null;
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// REACT HOOK
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { useState, useEffect, useCallback, useRef } from 'react';

export interface UseTranscriptionResult {
  status: TranscriptionStatus;
  segments: TranscriptSegment[];
  speakers: Speaker[];
  currentSegment: TranscriptSegment | null;
  error: string | null;
  start: (meetingId: string) => Promise<void>;
  stop: () => TranscriptionSession | null;
  pause: () => void;
  resume: () => void;
  setLanguage: (language: string) => void;
  setSpeakerName: (speakerId: string, name: string) => void;
  getTranscript: () => string;
  exportSRT: () => string;
  exportVTT: () => string;
  generateSummary: () => Promise<MeetingSummary>;
}

export function useTranscription(config?: Partial<TranscriptionConfig>): UseTranscriptionResult {
  const serviceRef = useRef<AITranscriptionService | null>(null);
  const [status, setStatus] = useState<TranscriptionStatus>('idle');
  const [segments, setSegments] = useState<TranscriptSegment[]>([]);
  const [speakers, setSpeakers] = useState<Speaker[]>([]);
  const [currentSegment, setCurrentSegment] = useState<TranscriptSegment | null>(null);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    serviceRef.current = new AITranscriptionService(config);
    
    serviceRef.current.onSegment((segment) => {
      if (segment.isFinal) {
        setSegments(prev => [...prev, segment]);
        setCurrentSegment(null);
      } else {
        setCurrentSegment(segment);
      }
    });

    serviceRef.current.onStatusChange(setStatus);
    
    serviceRef.current.onSpeakerChange(() => {
      const session = serviceRef.current?.getSession();
      if (session) {
        setSpeakers(Array.from(session.speakers.values()));
      }
    });

    serviceRef.current.onError((err) => {
      setError(err.message);
    });

    return () => {
      serviceRef.current?.destroy();
    };
  }, [config]);

  const start = useCallback(async (meetingId: string) => {
    setError(null);
    setSegments([]);
    setSpeakers([]);
    await serviceRef.current?.start(meetingId);
    
    const session = serviceRef.current?.getSession();
    if (session) {
      setSpeakers(Array.from(session.speakers.values()));
    }
  }, []);

  const stop = useCallback(() => {
    return serviceRef.current?.stop() || null;
  }, []);

  const pause = useCallback(() => {
    serviceRef.current?.pause();
  }, []);

  const resume = useCallback(() => {
    serviceRef.current?.resume();
  }, []);

  const setLanguage = useCallback((language: string) => {
    serviceRef.current?.setLanguage(language);
  }, []);

  const setSpeakerName = useCallback((speakerId: string, name: string) => {
    serviceRef.current?.setSpeakerName(speakerId, name);
    const session = serviceRef.current?.getSession();
    if (session) {
      setSpeakers(Array.from(session.speakers.values()));
    }
  }, []);

  const getTranscript = useCallback(() => {
    return serviceRef.current?.getTranscript() || '';
  }, []);

  const exportSRT = useCallback(() => {
    return serviceRef.current?.exportToSRT() || '';
  }, []);

  const exportVTT = useCallback(() => {
    return serviceRef.current?.exportToVTT() || '';
  }, []);

  const generateSummary = useCallback(async () => {
    if (!serviceRef.current) {
      throw new Error('Service not initialized');
    }
    return serviceRef.current.generateSummary();
  }, []);

  return {
    status,
    segments,
    speakers,
    currentSegment,
    error,
    start,
    stop,
    pause,
    resume,
    setLanguage,
    setSpeakerName,
    getTranscript,
    exportSRT,
    exportVTT,
    generateSummary
  };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXPORTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export { SUPPORTED_LANGUAGES };
